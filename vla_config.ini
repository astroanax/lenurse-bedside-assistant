# VLA Model Configuration for Bedside Assistant
# Vision-Language-Action model settings for pi0.5 integration

[model]
# HuggingFace model identifier
model_id = shehiin/pi05_pick_red_cube_lora
model_type = pi_zero
framework = lerobot

# Model architecture
input_image_size = 224
action_horizon = 10
history_length = 5

[inference]
# Inference settings
device = cpu  # Options: cpu, cuda
control_frequency = 10  # Hz
batch_size = 1

# Action smoothing
enable_smoothing = true
smoothing_window = 5

[safety]
# Safety constraints
max_joint_velocity = 200  # servo units per control step
enable_collision_detection = true
emergency_stop_enabled = true

# Joint limits for SO-101 5 DOF arm (servo units: 0-4095)
joint_1_min = 500
joint_1_max = 3500
joint_2_min = 500
joint_2_max = 3500
joint_3_min = 500
joint_3_max = 3500
joint_4_min = 500
joint_4_max = 3500
joint_5_min = 500
joint_5_max = 3500
gripper_min = 1024
gripper_max = 3072

[cache]
# Model caching
cache_dir = ./models/vla_cache
download_on_startup = false
use_cached_model = true

[fallback]
# Fallback behavior when VLA unavailable
enable_trajectory_fallback = true
trajectory_dir = ./trajectories
prefer_vla = true

[debug]
# Debug settings
log_predictions = true
save_input_images = false
verbose = false
